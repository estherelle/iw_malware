import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import (roc_curve, auc, accuracy_score)
import time

import pickle

import gc

from clean_data import load

# model imports
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.naive_bayes import BernoulliNB

from sklearn.model_selection import StratifiedKFold

# nohup python -u test_submissions.py > param_submit.out &

debug = False
# uncomment below if you want to run on the whole thing
# X = pd.read_csv("input/X.csv", nrows=1000)
X = pd.read_csv("input/X.csv")
y = np.load("input/y.npy")

if debug:
	y = y[:1000]

with open('best_parameters_2.pkl', 'rb') as f:
#     params = pickle.load(f)
    params = pickle.load(f)

# if debug:

# X_test = pd.read_csv("input/test_ohe.csv", nrows=1000)
X_test = pd.read_csv("input/test_ohe.csv")
# test_firewall = df_test = pd.read_csv('input/test.csv',
# 	usecols=['Firewall'], nrows=1000)
test_firewall = pd.read_csv('input/test.csv',
	usecols=['Firewall'])

X_test['Firewall'] = test_firewall['Firewall']
del test_firewall
X_test.replace({'Firewall': {np.nan: 0}}, inplace=True)

X.drop('Unnamed: 0', axis=1, inplace=True)
X_test.drop('Unnamed: 0', axis=1, inplace=True)

classifiers = {
	# "RandomForest": RandomForestClassifier(n_estimators=12),
	# "AdaBoostClassifier": AdaBoostClassifier(learning_rate=0.8),
	# # "GradientBoosting": GradientBoostingClassifier(),
	# "BernoulliNB": BernoulliNB(alpha=0.7),
	"LightGBM": lgb.LGBMClassifier(**params)
}

clfs = list(classifiers.keys())

df_test = pd.read_csv('input/test.csv',
	usecols=['MachineIdentifier'])
# df_test = pd.read_csv('input/test.csv',
# 	usecols=['MachineIdentifier'])

for clf in clfs:
	start = time.time()
	mdl = classifiers[clf]
	print("Proceeding to fit the %s model" %clf)


	# if clf == "LightGBM":
	# 	folds = StratifiedKFold(n_splits=5, shuffle=True)

	# 	print("Beginning training")
	# 	ct = 0
	# 	for idxT, idxV in folds.split(X, y):
	# 		# print(idxT, type(idxT))
	# 		# print(idxV, type(idxV))
	# 	    # TRAIN LGBM
	# 		ct += 1
	# 		print('####### FOLD ',ct,'#########')
	# 		df_trainA = X.loc[idxT,]
	# 		y_A = np.take(y, idxT)
	# 		df_trainB = X.loc[idxV]
	# 		y_B = np.take(y, idxV)
	# 		model = mdl

	# 		h=model.fit(df_trainA, y_A, eval_metric='auc',
	# 			eval_set=[(df_trainB, y_B)], verbose=200,
	# 			early_stopping_rounds=100)

	# 		# PREDICT TEST
	# 		del df_trainA, df_trainB, y_A, y_B; x=gc.collect()
	# 		idx = 0; ct2 = 1; 

	# 		if not debug:
	# 			chunk = 1000000
	# 		else:
	# 			chunk = 100
				
	# 			while idx < len(X_test):
	# 				idx2 = min(idx + chunk, len(X_test) )
	# 				idx = range(idx, idx2)
	# 				pred_val[idx] += model.predict_proba(X_test.iloc[idx])[:,1]
	# 			    #print('Finished predicting part',ct2)
	# 				ct2 += 1; idx = idx2
	# 		print("Time taken:", time.time() - start)
	# 	pred_val /= 5
	# else:
	mdl.fit(X, y)
	print("Model fit complete- moving on to predict")

	pred_val = mdl.predict_proba(X_test)[:, 1]
		# print(pred_val)
		# print(pred_val[:,1] == pred_val[::, 1])

	# mdl.fit(X, y)
	# print("Model fit complete- moving on to predict")

	# prob_pred = mdl.predict_proba(X_test)

	time_taken = time.time() - start

	print("Finished predictions in %d seconds, saving predictions to submissions folder" %time_taken)


	df_test['HasDetections'] = pred_val
	df_test[['MachineIdentifier','HasDetections']].to_csv('submissions/submission_%s_ht2.csv' %clf, index=False)


