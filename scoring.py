import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
import time

from clean_data import load

import pickle

# model imports
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.naive_bayes import BernoulliNB
# from sklearn.model_selection import StratifiedKFold

from sklearn.metrics import roc_curve, log_loss, brier_score_loss, roc_auc_score

debug = False

print("Loading the data")

y_train = np.load("input/y_train.npy")
y_test = np.load("input/y_test.npy")


print("Data loaded")
if debug:
	X_train = pd.read_csv("input/X_train.csv", nrows=1200)
	y_train = y_train[:1000]
	X_test = X_train[1000:1200]
	X_train = X_train[:1000]
	y_test = y_test[1000:1200]
else:
	X_train = pd.read_csv("input/X_train.csv")
	X_test = pd.read_csv("input/X_test.csv")

X_train.drop('Unnamed: 0', axis=1, inplace=True)
X_test.drop('Unnamed: 0', axis=1, inplace=True)



with open('best_parameters_2.pkl', 'rb') as f:
#     params = pickle.load(f)
    params = pickle.load(f)
classifiers = {
	"RandomForest": RandomForestClassifier(n_estimators=12),
	"AdaBoostClassifier": AdaBoostClassifier(learning_rate=0.8),
	# "GradientBoosting": GradientBoostingClassifier(),
	"BernoulliNB": BernoulliNB(alpha=0.7),
	"LightGBM": lgb.LGBMClassifier(**params)
}

clfs = list(classifiers.keys())
test_num = 4

rows_list = []

def pr_metrics(y_test, y_pred):
    fpr, tpr, _ = roc_curve(y_test,  y_pred)
#     auc = metrics.roc_auc_score(y_test, y_pred)
    
    return fpr, tpr

for clf in clfs:
	start = time.time()
	mdl = classifiers[clf]
	print("Proceeding to fit the %s model" %clf)

	mdl.fit(X_train, y_train)
	print("Model fit complete- moving on to predict")

	# bin_pred = mdl.predict(X_test)
	y_pred = mdl.predict_proba(X_test)[::, 1]

	time_taken = time.time() - start

	print("Finished predictions in %d seconds, saving predictions in input folder" %time_taken)

	# np.save("input/%s_bin_%d.npy" %(clf, test_num), bin_pred)
	np.save("input/%s_prob_%d.npy" %(clf, test_num), y_pred)

	
	print("Completed, total time taken:", time.time() - start, "\n")

	auc = roc_auc_score(y_test, y_pred)
	f, t = pr_metrics(y_test, y_pred)

	detail_dict = {
		"Model": clf,
		"AUC": auc,
		"True Positive Rate": np.mean(f),
		"False Positive Rate": np.mean(t),
		"Log Loss Score": log_loss(y_test, y_pred),
		'Brier Score': brier_score_loss(y_test, y_pred),
		"Prob_file": "input/%s_prob_%d.npy" %(clf, test_num),
		"Time": time_taken
	}
        
        print(detail_dict)
        rows_list.append(detail_dict)

	# uncomment below if you want to run on the whole thing
	# X = pd.read_csv("input/X.csv")
	# y = np.load(y, "input/y.npy")


df = pd.DataFrame(rows_list)
df.to_csv("output_%d.csv" %test_num, index=False)


